% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.21 of 2022/01/12
%
\documentclass[runningheads]{llncs}
%
\usepackage[T1]{fontenc}
% T1 fonts will be used to generate the final print and online PDFs,
% so please use T1 fonts in your manuscript whenever possible.
% Other font encondings may result in incorrect characters.
%
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[table,xcdraw]{xcolor}
\usepackage{helvet,times,courier}
\usepackage{multirow}
\usepackage{algorithm2e}
\SetKwInput{KwParam}{Parameters}
\SetKw{KwFrom}{from}
\SetCommentSty{textit}

\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following two lines
% to display URLs in blue roman font according to Springer's eBook style:
%\usepackage{color}
%\renewcommand\UrlFont{\color{blue}\rmfamily}
%\urlstyle{rm}
%
\sloppy
\hyphenation{make-span}
\begin{document}
%
\title{Swarm Intelligence-Driven Dispatching Rules for Large-Scale Semiconductor Production: Integrating Simulation and Optimization to Enhance Operational Efficiency
}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Ramsha Ali\inst{1}\orcidID{0000-0002-4794-6560} \and
Peyman Eftekhari\inst{1}\orcidID{0009-0007-4198-392X} \and
Martin Gebser\inst{1}\orcidID{0000-0002-8010-4752} \and
Stephan Leitner\inst{2}\orcidID{0000-0001-6790-4651} \and
Gerhard Friedrich\inst{1}\orcidID{0000-0002-1992-4049}
}
%
\authorrunning{R. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Department of Artificial Intelligence and Cybersecurity, \and
	Department of Management Control and Strategic Management, \\ University of Klagenfurt, Austria \\
	\email{\{ramsha.ali,peyman.eftekhari,martin.gebser, \\ stephan.leitner,gerhard.friedrich\}@aau.at} \\
	\url{https://www.aau.at}}

%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The escalating complexity of semiconductor production, characterized by high-volume, low-mix and low-volume, high-mix environments, demands advanced dispatching strategies that transcend traditional rule-based systems. This paper introduces a novel set of dispatching rules derived from Swarm Intelligence techniques, specifically designed to tackle the intricate dynamics of large-scale semiconductor manufacturing. The research integrates simulation and optimization methodologies to investigate and enhance operational efficiency, addressing both the scalability of solutions and their practical implementation. We employ a customizable simulation framework to model a semiconductor manufacturing environment, wherein various dispatching rules, including FIFO, CR, RANDOM, and our proposed SI-driven method, are assessed. The core of our approach lies in its ability to adaptively reconfigure scheduling priorities based on real-time production dynamics, thus significantly improving the responsiveness and throughput of manufacturing processes.
The effectiveness of these dispatching rules is quantitatively evaluated through a series of simulations that measure key performance indicators such as Work in Progress (WIP) levels, throughput, and operational variability across different production scenarios.
This study not only elucidates the potential of swarm intelligence in refining production dispatching but also provides a framework that incorporates scalable simulation tool that can assist in the further development of intelligent dispatching systems. 

\keywords{Swarm intelligence \and Ant colony optimization \and Greedy search \and Semiconductor production \and Scheduling \and Dispatching \and Simulation}
\end{abstract}
%
%
%
\section{Introduction}
\label{sec:introduction}
As the digital transformation deepens across various sectors, the demand for more powerful, energy-efficient, and smaller semiconductors continues to escalate. This surge in demand places immense pressure on semiconductor manufacturers to scale up production without compromising quality. Semiconductor production involves hundreds of sophisticated steps, each of which must be precisely controlled to ensure the functionality and yield of the final product \cite{kopp2020smt2020}. The complexity is exacerbated by the rapid pace of innovation in semiconductor design, which frequently shifts production parameters and process requirements.

Dispatching and scheduling are critical in semiconductor manufacturing because they directly impact the throughput and utilization of resources. Dispatching refers to the process of assigning work to specific machines in real-time, while scheduling involves pre-planning the sequence and timing of operations to optimize certain objectives, such as minimizing the total completion time or balancing the load across different machines \cite{schumann2022scheduling}.

For smaller volumes at workcenters in the fab, which are modeled as flexible job shops, optimal solutions can be achieved using mathematical optimization \cite{waschneck2018deep}. However, in larger and more dynamic environments, the complexity and computational time constraints limit the feasibility of applying mathematical optimization. Consequently, optimization is typically implemented on a local scale, isolated to individual workcenters. In complex job shop scenarios, this localized approach to production scheduling may lead to solutions that are globally sub-optimal.

The complexity of scheduling is intensified by the unpredictable nature of processing times and machine availability. Variability in processing times may arise from differences in equipment performance, material handling durations, or the unique characteristics of each set of wafers. Furthermore, frequent machine breakdowns can lead to substantial disruptions, underscoring the need for strong and adaptable scheduling strategies \cite{leachman1996benchmarking}.

Dispatching in semiconductor production is a particularly challenging aspect of factory operations. It involves determining the sequence and timing of various production tasks, from wafer fabrication to assembly and testing, to maximize throughput \cite{Hopp2011}. In large-scale operations, the complexity is magnified by the sheer number of variables involved, including machine availability, maintenance schedules, workforce shifts, and rapidly changing order priorities. Traditional dispatching solutions often fall short in such an environment, as they cannot adequately adapt to the dynamic and complex nature of semiconductor production. This inadequacy can lead to sub-optimal decisions that compromise operational efficiency and product quality \cite{Uzsoy1992}.

On the other hand, scheduling in large-scale semiconductor production is a cornerstone of operational management that directly influences the effectiveness and efficiency of the entire manufacturing process \cite{schumann2022scheduling}. It involves planning and organizing production activities to ensure that resources are utilized optimally and product flows are synchronized across various stages of the manufacturing process. Effective scheduling is critical not only for maintaining high throughput but also for minimizing production delays and reducing inventory and holding costs.

The scheduling of semiconductor manufacturing is notably complex due to the high variability in production processes, the sensitive nature of the materials involved, and the stringent quality requirements \cite{May2006}. Each semiconductor product may pass through hundreds of processing steps, requiring precise timing and coordination. Moreover, the high mix of product types, each with different processing needs and priorities, adds another layer of complexity \cite{Mönch2011}. This complexity is further exacerbated by the need to integrate new product introductions seamlessly into the production schedule without disrupting ongoing operations.

Scheduling production operations within the intricate landscape of semiconductor manufacturing represents one of the most daunting challenges in resource allocation. The dynamic nature of manufacturing environments—characterized by unpredictable fluctuations in process and demand, supply chain delays, and frequent machine breakdowns—significantly intensifies this complexity. Consequently, production scheduling must not only strive for near-optimal outcomes but also maintain robustness and flexibility to adapt swiftly to frequent changes in the production landscape. 

In this paper, we explore the complexities of scheduling within large-scale Semiconductor Manufacturing Scheduling Problems (SMSP), commonly referred to as fabs. Fabs are intricate production settings distinguished by their specialized job flows and advanced machinery. Modern semiconductor fabs manage the processing of tens of thousands of operations daily across over 1000 different machines \cite{kopp2020smt2020}. These machines are grouped by functionality—such as diffusion, etching, or metrology—and each step in the manufacturing process can be assigned to any machine that offers the necessary capabilities. The scheduling challenge in semiconductor production thus involves assigning specific operations to appropriate machines and determining the optimal sequence of these operations on each machine. Additionally, schedules must be flexible and capable of rapid adjustments in response to machine failures or deviations in the process.

In our previous work \cite{Ali2024}, we proposed a Greedy Search based Ant Colony Optimization (GSACO)
algorithm for (re-)scheduling semiconductor production operations \cite{Ali2024}. 
Our algorithm harnesses Ant Colony Optimization (ACO) \cite{Dorigo2019} for exploration, while
Greedy Search (GS) \cite{Papadimitriou} enables responses in short time. 
In this way, GSACO overcomes limitations of a state-of-the-art Constraint Programming approach \cite{Perron2023}
on large-scale SMSP instances. Our approach synergistically combines probabilistic operation sequencing with a greedy machine assignment strategy, targeting up to five operations per lot with the primary objective of minimizing makespan. Building on this foundational work, the current paper extends these initial concepts by proposing an enhanced algorithm, GSACO-I, specifically designed to optimize operational throughput. This development marks a significant advancement in our methodology, aiming to refine the dispatching rules further though simulation.

The paper is organized as follows. 
Section~\ref{sec:lit_rev} provides literature review.
In Section~\ref{sec:problem_f}, we formulate SMSP in terms of the well-known flexible job shop scheduling problem (FJSSP). 
% and Section \ref{sec:aco} describes the overview of the ACO approach. 
Our GSACO-1 algorithm is presented in Section~\ref{sec:gsaco}.
In Section~\ref{sec:sim} we present the customized simulation adopted from \cite{Kovács2022}.
Section~\ref{sec:results} provides and discusses experimental results.
Finally, Section~\ref{sec:conclusion} concludes the paper.

\section{literature Review}
\label{sec:lit_rev}
\input{lit_review.tex}

\section{Problem Formulation}
\label{sec:problem_f}

\begin{table*}[t]
	\caption{Basic notations (adapted from \cite{Ali2024})}\label{notations} \centering
	\begin{tabular}{|l|l|}
		\hline
		Symbol & Description \\ \hline
		$J$ & Total number of \emph{jobs}        \\
		$T$ & Total number of \emph{tool groups} \\
		$M$ & Total number of \emph{machines}    \\
		$N$ & Total number of \emph{operations} \\
		$t_{m}$ & Tool group $t$ of machine $m$ \\
		$O_{i,j,t}$ & Operation $i$ of job $j$ on tool group $t$  \\
		$d_{i,j,t}$ & \emph{Duration} of operation $O_{i,j,t}$ on tool group $t$ \\
		$O_{i,j,t,m}$ & Operation $i$ of job $j$ on machine $m$ of tool group $t$  \\
		$s_{i,j,t,m}$ & \emph{Start time} of operation $O_{i,j,t}$ on machine $m$ of tool group $t$  \\
		\hline
	\end{tabular}
\end{table*}

We formulate SMSP in terms of the general FJSSP model,
using the basic notations listed in Table~\ref{notations} (see \cite{Ali2024}). 
In detail, our setting for scheduling the production of a semiconductor fab is characterized as follows:

\begin{itemize}
	\item The fab consists of $M$ machines, which are partitioned into $T$
	tool groups, where $t_m\in\{1,\dots,T\}$ denotes the tool group
	to which a machine $m\in\{1,\dots,M\}$ belongs.
	\item There are $J$ jobs, where each $j\in\{1,\dots,J\}$ represents a
	sequence of operations $O_{1,j,t_1},\dots,O_{n_j,j,t_n}$, to be performed on a production lot.
	Note that $t_i\in\{1,\dots,T\}$ specifies the tool group 
	responsible for processing an operation $O_{i,j,t_i}$, % for $i\in\{1,\dots,n_j\}$
	but not a specific machine of $t_i$,
	which reflects flexibility in assigning operations to machines.
	The total number of operations is denoted by
	$N = \sum_{j\in\{1,\dots,J\}}n_j$.
	\item For each operation $O_{i,j,t}$,
	the duration $d_{i,j,t}$ is required for processing $O_{i,j,t}$
	on some machine of the tool group~$t$.
\end{itemize}

Our SMSP model incorporates key features drawn from the semiconductor production 
scenarios outlined in the SMT2020 dataset \cite{kopp2020smt2020}. 
In these scenarios, each job corresponds to a specific product, 
with operation sequences—referred to as production routes—remaining 
consistent across the same product type. Given that these production routes 
can span several months and encompass hundreds of operations within a physical fab, 
it's common for different lots of the same product to be at various stages 
of their production routes during (re-)scheduling. 
Therefore, our model does not differentiate production routes by product; 
instead, we focus on the operation sequences of a specific length $n_j$ related to each job~$j$. 
This approach facilitates the management of operations for lots at different stages within the same production route.

Moreover, the machines belonging to a tool group are assumed to be uniform,
i.e., an operation requiring the tool group can be processed by any of its
machines.
This simplifying assumption ignores specific machine setups, which may be
needed for some operations and take additional equipping time,
as well as unavailabilities due to maintenance procedures or breakdowns.
However, the greedy machine assignment performed by our GSACO algorithm
in Section~\ref{sec:gsaco} can take such conditions into account for
allocating an operation to the earliest available machine.
In addition, some transportation time is required to move
a lot from one machine to another between operations,
which is not explicitly given but taken as part of the operation duration
in the SMT2020 scenarios.

\begin{table}[t]
	\caption{GSACO parameters}\label{tab:parameters} \centering
	\begin{tabular}{|l|l|}
		\hline
		Parameter & Description \\ \hline
		$o$ & Objective \\
		$s$ & State \\
		$l$ & Cycles/time limit        \\
		$n$ & Operations per lot \\
		$h$ & Planning period \\
		$k$ & Number of ants \\
		$\tau_{y}$ & Initial pheromone level \\
		$\tau_{z}$ & Minimum pheromone level \\
		$\tau_{e}$ & Pheromone level on edge $e$ \\
		%	$\eta_{e}$ & Heuristic information on edge $e$ \\
		$\rho$ & Evaporation rate \\
		$c$ & Contribution of best schedules \\
		%	$\alpha$ & Influence of pheromone $\tau_{e}$ \\
		%	$\beta$ & Influence of heuristic $\eta_{e}$    \\
		\hline
	\end{tabular}
\end{table}

A schedule allocates each operation $O_{i,j,t}$ to some machine
$m\in\{1,\dots,M\}$ such that $t_m=t$, and we denote the machine
assignment by $O_{i,j,t,m}$.
Each machine performs its assigned operations in sequence without
preemption, i.e.,
$s_{i,j,t,m} + d_{i,j,t} \leq s_{i',j',t,m}$ or
$s_{i',j',t,m} + d_{i',j',t} \leq s_{i,j,t,m}$
must hold for the start times
$s_{i,j,t,m}$ and $s_{i',j',t,m}$ of operations
$O_{i,j,t,m}\neq O_{i',j',t,m}$
allocated to the same machine~$m$.
The precedence between operations of a job $j\in\{1,\dots,J\}$ needs to be
respected as well, necessitating that
$s_{i,j,t,m} + d_{i,j,t} \leq s_{i+1,j,t',m'}$ when $i<n_j$.
Assuming that $0\leq s_{1,j,t,m}$ for each job $j\in\{1,\dots,J\}$,
the makespan to complete all jobs is given by
$\max\{s_{n_j,j,t,m} + d_{n_j,j,t} \mid j\in\{1,\dots,J\}\}$.
We take makespan minimization as the primary optimization objective for scheduling, as it reflects efficient machine utilization and maximization of fab throughput. Additionally, we aim to optimize the number of operations completed within a specified period, enhancing overall productivity and operational efficiency. This approach ensures not only the effective use of available machinery but also strives to maximize the output within time constraints, thereby optimizing operational flow and throughput within the manufacturing process.


\begin{figure}[t]
	\includegraphics[width=\textwidth]{schedule_example_makespan.png}
	\caption{Feasible schedule for the operations in Table~\ref{tab:instance}}
	\label{fig:sch-makespan}
\end{figure}
\begin{figure}[t]
	\includegraphics[width=\textwidth]{schedule_example_operations.png}
	\caption{Feasible schedule for the operations in Table~\ref{tab:instance}}
	\label{fig:sch-operations}
\end{figure}

An example schedule (generated by GSACO) for instance in Table~\ref{tab:instance} 
is displayed in Figure~\ref{fig:sch-makespan} and Figure~\ref{fig:sch-operations}.


\section{GSACO Algorithm}
\label{sec:gsaco}

The structure of our proposed GSACO algorithm, along with its input and internal parameters, 
is summarized in Table~\ref{tab:parameters} and 
illustrated in Figure~\ref{fig:aco-flowchart}. 
The four main submodules, highlighted in bold, are discussed in detail in the following subsections.

Moreover, Algorithm~\ref{gsaco} provides a pseudo-code representation of
GSACO for minimizing makespan and optimizing operations.

For a configurable cycle number or time limit~$l$,
each of the $k$ ants applies greedy search
using the GS procedure with respect to the objective.
That is, the first GS phase constructs an operation sequence, which is
then taken as basis for greedily assigning the operations to machines
in the second phase.   
Note that the ants run independently, so that their GS trials
can be performed in parallel.
As a result, $k$ schedules along with edges between operations
(described in Subsection~\ref{subsec:initialization})
that have been selected for their construction are obtained.
If some of these schedules improves the makespan over the best
schedule found in previous iterations (if any),
the best schedule gets updated.
As common for ACO algorithms,
pheromones $\tau_e$ on edges~$e$ are subject to evaporation,
according to the formula $\rho\cdot\tau_e$,
while edges selected to construct the best schedule obtained
so far also receive a pheromone contribution,
calculated as $\tau_e+c$.
Such pheromone deposition increases the chance for edges contributing to the
current best schedule
to get re-selected % by the GS procedure
in forthcoming iterations.

\begin{figure}[t]
	\includegraphics[width=\textwidth]{aco-flowchart.png}
	\caption{GSACO framework}
	\label{fig:aco-flowchart}
\end{figure}

\begin{algorithm}[t]
	\caption{Greedy Search based ACO (GSACO) for Scheduling}
	\label{gsaco}
	\KwIn{instance, $l$, $o$, $s$, $n$, $h$, $\text{objective}$}
	\KwOut{best schedule found by ants}
	\KwParam{$k$, $\tau_{y}$, $\tau_{z}$, $\rho$, $c$}
	Initialize adjacency, pheromone, and machine matrix\; 
	\eIf{\text{objective} == \text{Makespan}}{
		$\mathit{makespan}\leftarrow \infty$\;
	}{
		$\mathit{operations}\leftarrow 0$\;
	}
	\While{cycle or time limit $l$ is not reached}{
		\ForEach{ant \KwFrom $1$ \KwTo $k$}{
			Run GS procedure to find a schedule\;
		}
		\eIf{\text{objective} == \text{Makespan}}{
			$\mathit{new}\leftarrow$ shortest makespan of ants' schedules\;
			\If{$\mathit{new}<\mathit{makespan}$}{
				$\mathit{makespan}\leftarrow \mathit{new}$\;
				$\mathit{best}\leftarrow$ an ant's schedule of minimum $\mathit{makespan}$\;
			}
		}{
			$\mathit{new}\leftarrow$ maximum operations of ants'\;
			\If{$\mathit{new}>\mathit{operations}$}{
				$\mathit{operations}\leftarrow \mathit{new}$\;
				$\mathit{best}\leftarrow$ an ant's schedule of maximum $\mathit{operations}$\;
			}
		}
		\ForEach{edge $e$ in pheromone matrix}{
			$\tau_{e} \leftarrow \max\{\rho\cdot\tau_e,\tau_z\}$\tcp*[r]{evaporation}
		}
		\ForEach{edge $e$ selected by $\mathit{best}$ ant}{
			$\tau_{e} \leftarrow \tau_e+c$\tcp*[r]{deposit pheromones}
		}
	}
	\Return $\mathit{best}$\;
\end{algorithm}


\subsection{Input Module}

This module reads in an SMSP instance from the SMT2020 simulation develop by \cite{Kovács2022}, 
and SMT2020 dataset \cite{kopp2020smt2020}.
The instance includes tool groups with their respective machines, jobs currently in progress, and production routes. In terms of dynamic state, the processing times for these routes are stochastic. Conversely, the simulator provides observed averages for processing times and job releases. Additionally, the module takes several inputs for the GSACO optimization process: the objective~$o$, the state of the fab~$s$, planning period~$h$, 
operation per lot~$n$ and a limit~$l$ on either the number of cycles or the time allocated for optimization.


\subsection{Initialization Module}
\label{subsec:initialization}
In view of long production routes with hundreds of operations
in the SMT2020 dataset, we introduce a configurable planning horizon~$n$
as upper bound on the length $n_j$ of the operation sequence for a job~$j$.
The planning horizon thus constitutes a scaling factor for the size and
the resulting complexity of SMSP instances.
% This horizon is crucial in planning and decision-making, especially within large-scale production systems. 
In practice, unpredictable stochastic events make long-term schedules obsolete and necessitate frequent re-scheduling,
where limiting the planning horizon upfront provides a means to
control the search and enable short response times.

To express SMSP as a search problem on graphs,
we identify an instance with the disjunctive graph

whose vertices~$V$ contain the operations $O_{i,j,t}$ plus
a dummy start node~$0$,
conjunctive edges\linebreak[1]%
%
\begin{equation}
	\begin{array}{@{}r@{}l@{}}
		E_c = {}
		& \{(0,O_{1,j,t_1}) \mid O_{1,j,t_1}\in V\}
		\\ {} \cup {}
		& \{(O_{i-1,j,t_{i-1}},O_{i,j,t_i}) \mid O_{i,j,t_i}\in V, i > 1\}
	\end{array}
\end{equation}
%
connect the dummy start node~$0$ to the first operation
and each operation on to its successor (if any) in the sequence for a job,
and disjunctive edges\linebreak[1]%
%
\begin{equation}
	E_d = \{(O_{i,j,t},O_{i',j',t}) \mid O_{i,j,t}\in V,O_{i',j',t}\in V, j\neq j'\}
\end{equation}
%
link operations (of distinct jobs) sharing a common tool group,
as such operations may be allocated to the same machine.

Any feasible schedule induces an acyclic subgraph $(V,E)$ of 
the disjunctive graph~$G$
such that $E_c\subseteq E$, and $(O_{i,j,t},O_{i',j',t})\in E_d\cap E$
iff $s_{i,j,t,m}+d_{i,j,t} < s_{i',j',t,m}$ for distinct jobs $j\neq j'$,
i.e., the operation
$O_{i,j,t}$ is processed before $O_{i',j',t}$ by the same machine~$m$
of tool group $t_m=t$.
Conversely,
the search for a high-quality solution can be accomplished by
determining an acyclic subgraph $(V,E)$ of~$G$ that represents a schedule
of short makespan.

For example, Table~\ref{tab:operations} shows operations
belonging to five jobs, as they can
be obtained with the parameter $n=5$ for the planning period.
Conjunctive edges connect the dummy start node~$0$ to
the operations which come first in their jobs and all operations to their successors.
In addition, mutual disjunctive edges link operations
to be processed on the same tool group.
The resulting $(N+1)\times(N+1)$ adjacency matrix, where $N$ is the
total number of operations, $0$ entries indicate the absence, and
$1$ entries the existence of edges, is given in Figure~\ref{fig:a}.

\begin{table}[t]
	\caption{Example operations}\label{tab:operations} \centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		No. & Operation & Tool group name & Avg process time (sec)\\ \hline
		$1$ & $O_{1,1,2}$ & TF\_Met\_FE\_45 & $588$ \\
		$2$ & $O_{2,1,3}$ & WE\_FE\_108 & $59$ \\
		$3$ & $O_{3,1,4}$ & WE\_FE\_83 & $62$ \\
		$4$ & $O_{4,1,5}$ & WE\_FE\_84 & $54$ \\
		$5$ & $O_{5,1,1}$ & LithoTrack\_FE\_115 & $130$ \\
		$6$ & $O_{1,2,2}$ & TF\_Met\_FE\_45    & $588$ \\
		$7$ & $O_{2,2,3}$ & WE\_FE\_108 & $59$ \\
		$8$ & $O_{3,2,4}$ & WE\_FE\_83         & $62$ \\
		$9$ & $O_{4,2,5}$ & WE\_FE\_83    & $54$ \\
		$10$ & $O_{5,2,1}$ & LithoTrack\_FE\_115 & $130$ \\
		$11$ & $O_{1,3,2}$ & TF\_Met\_FE\_45         & $588$ \\
		$12$ & $O_{2,3,3}$ & WE\_FE\_108    & $59$ \\
		$13$ & $O_{3,3,4}$ & WE\_FE\_83 & $62$ \\
		$14$ & $O_{4,3,5}$ & WE\_FE\_84         & $54$ \\
		$15$ & $O_{5,3,1}$ & LithoTrack\_FE\_115    & $130$ \\
		$16$ & $O_{1,4,2}$ & TF\_Met\_FE\_45 & $588$ \\
		$17$ & $O_{2,4,3}$ & WE\_FE\_108         & $59$ \\
		$18$ & $O_{3,4,4}$ & WE\_FE\_83    & $62$ \\
		$19$ & $O_{4,4,5}$ & WE\_FE\_84 & $54$ \\
		$20$ & $O_{5,4,1}$ & LithoTrack\_FE\_115         & $130$ \\
		$21$ & $O_{1,5,2}$ & TF\_Met\_FE\_45   & $588$ \\
		$22$ & $O_{2,5,3}$ & WE\_FE\_108 & $59$ \\
		$23$ & $O_{3,5,4}$ & WE\_FE\_83         & $62$ \\
		$24$ & $O_{4,5,5}$ & WE\_FE\_84    & $54$ \\
		$25$ & $O_{5,5,0}$ & LithoTrack\_FE\_115 & $115$ \\
		\hline
	\end{tabular}
\end{table}

\begin{table}[t]
	\caption{Example instance}\label{tab:instance} \centering
	\begin{tabular}{|l|l|l|}
		\hline
		Lot & Product & Step \\ \hline
		$1$ & $1$ & $1$ \\
		$2$ & $2$ & $2$  \\
		$3$ & $3$ & $1$ \\
		$4$ & $4$ & $3$ \\
		$5$ & $5$ & $1$ \\
		$1$ & $1$ & $2$     \\
		$2$ & $2$ & $1$  \\
		$3$ & $3$ & $3$        \\
		$4$ & $4$ & $1$     \\
		$5$ & $5$ & $2$  \\
		\hline
	\end{tabular}
\end{table}
%

\begin{figure}[h]
	\centering
	\begin{minipage}{.45\columnwidth}
		\centering
		$\begin{array}{c@{}c}
			& \begin{array}{cccccccccc} 0 & 1 & 2 & \dots & 41 & 42 & 43 \end{array} \\
			\begin{array}{c} 0 \\ 1 \\ 2 \\ \vdots \\ 41 \\ 42 \\ 43 \end{array} &
			\left[\begin{array}{ccccccccc}
				0 & 1 & 0 & \dots & 0 & 0 & 1 \\ 
				0 & 0 & 1 & \dots & 0 & 0 & 0 \\ 
				0 & 0 & 0 & \dots & 1 & 0 & 0 \\ 
				\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
				0 & 0 & 0 & \dots & 0 & 1 & 0 \\ 
				0 & 0 & 0 & \dots & 0 & 0 & 1 \\ 
				0 & 0 & 1 & \dots & 0 & 0 & 0 \\
			\end{array}\right]
		\end{array}$
		\caption{Adjacency matrix for instance in Table~\ref{tab:instance}}
		\label{fig:a}
	\end{minipage}\hfill
	\begin{minipage}{.45\columnwidth}
		\centering
		$\begin{array}{c@{}c}
			& \begin{array}{cccccccccccc} 1 & 2 & 3 & \dots & 10 & 11 & 12 \end{array} \\
			\begin{array}{c} 0 \\ 1 \\ 2 \\ \vdots \\ 41 \\ 42 \\ 43 \end{array} &
			\left[\begin{array}{cccccccccccc}
				0 & 1 & 0 & \dots & 0 & 0 & 0 \\ 
				0 & 0 & 1 & \dots & 0 & 0 & 0 \\ 
				0 & 0 & 0 & \dots & 1 & 0 & 0 \\ 
				\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
				0 & 0 & 0 & \dots & 0 & 1 & 0 \\ 
				0 & 0 & 0 & \dots & 0 & 0 & 1 \\ 
				0 & 0 & 1 & \dots & 0 & 0 & 0 \\
			\end{array}\right]
		\end{array}$
		\caption{Machine matrix for instance in Table~\ref{tab:instance}}
		\label{fig:b}
	\end{minipage}
\end{figure}

As initial pheromone level on edges $e\in E_c\cup E_d$,
we take $\tau_y=1$ by default.
In general, representing pheromone levels by an $(N+1)\times(N+1)$
matrix similar to the adjacency matrix,
the entries~$\tau_{e}$ are initialized according to the following condition:\linebreak[1]%

\begin{equation}
	\tau_{e} =
	\begin{cases}
		\tau_y & \text{if $e\in E_c\cup E_d$} \\
		0      & \text{otherwise}
	\end{cases}
\end{equation} 
 
With $\tau_y=1$, this reproduces the adjacency matrix in Figure~\ref{fig:a}
as initial pheromone matrix for our example.

We additionally represent the possible machine assignments
by an $(N+1)\times M$ machine matrix, where $M$ is the total number of
machines.
For example, with two machines per tool group and the mapping
$t_m=\lceil \frac{m}{2} \rceil$ from machine identifiers
$m\in \{1,\dots,12\}$ to the tool groups $t\in\{1,\dots,6\}$,
responsible for processing the remaining operations in Table~\ref{tab:instance},
we obtain the machine matrix shown in Figure~\ref{fig:b}.

\subsection{GS Module}

The general goal of greedy search methods consists of using heuristic decisions
to find high-quality, but not necessarily optimal solutions in short time.
Within GSACO, each ant applies greedy search to efficiently construct some
feasible schedule for a given SMSP instance.
The respective GS procedure, outlined by the pseudo-code in Algorithm~\ref{gs-m} and Algorithm~\ref{gs-o},
includes two phases: 
operation sequencing and machine assignment.
%

\begin{algorithm}[t]
	\caption{Greedy Search (GS) Makespan}
	\label{gs-m}
	\KwOut{schedule and selected edges of an an\rlap{t}}
	$\mathit{sequence}\leftarrow[]$\;
	$\mathit{selected}\leftarrow\emptyset$\;
	$\mathit{next}\leftarrow\{(0,O_{1,j,t}) \mid j\in\{1,\dots,J\}\}$\;
	%	\lForEach{$m\in\{1,\dots,M\}$}{$f_m\leftarrow 0$}
	\While{$\mathit{next}\neq\emptyset$}{
		%	$\mathit{\tau}=\sum_{e\in\mathit{next}}\tau_e$\;
		\lForEach{$e\in\mathit{next}$}{%}
		$p_e\leftarrow \frac{\tau_e}{\sum_{e'\in\mathit{next}}\tau_{e'}}$}
	Randomly select an edge $e$ based on $p_e$\;
	\For{selected edge $e=(O',O_{i,j,t})$}{
		$\mathit{sequence}.\mathrm{enqueue}(O_{i,j,t})$\;
		$\mathit{selected}\leftarrow\mathit{selected}\cup\{e\}$\;
		$\mathit{next}\leftarrow\{(O_1,O_2)\in\mathit{next} \mid O_2\neq O_{i,j,t}\}$\;
		$\begin{array}{@{}r@{}l@{}}
			E \leftarrow {} &		
			\{(O_{i,j,t},O_{{i+1},j,t'}) \mid i<n_j\}
			%	  \cup {}
			\\ {} \cup {} &
			\{(O_{i,j,t},O_{i',j',t}) \mid (O_1,O_{i',j',t})\in\mathit{next}\}\text{\;}
		\end{array}$
		$\mathit{next}\leftarrow\mathit{next}\cup E$\;
		}}
		\lForEach{$m\in\{1,\dots,M\}$}{$a_m\leftarrow 0$}
		\While{$\mathit{sequence}\neq[]$}{
			$O_{i,j,t}\leftarrow\mathit{sequence}.\mathrm{dequeue}()$\;
			$a \leftarrow \infty$\;
			%	$b \leftarrow 0$\;
			\ForEach{$m$ \KwFrom $1$ to \KwTo $M$}{
				\If{$t_m = t$ and $a_m < a$}{
					$a\leftarrow a_m$\;
					$b\leftarrow m$\;
				}
			}
			%	\If{$0<b$}{
				$\begin{array}{@{}r@{}l@{}}
					s_{i,j,t,b}\leftarrow 
					\max(&\{a\}
					\\ {} \cup {} &
					\{s_{i-1,j,t',m}+d_{i-1,j,t'}\mid{}i>1\})\text{\;}
				\end{array}
				$
				$a_b \leftarrow s_{i,j,t,b}+d_{i,j,t}$\;
				%	}
		}
		\Return $\langle\{s_{i,j,t,m} \mid (O',O_{i,j,t})\in\mathit{selected}\},{}$\rlap{$\mathit{selected}\rangle$\;}
\end{algorithm}


\begin{algorithm}[t]
	\caption{Greedy Search (GS) Operations}
	\label{gs-o}
	\KwOut{schedule and selected edges of an an\rlap{t}}
	$\mathit{sequence}\leftarrow[]$\;
	$\mathit{selected}\leftarrow\emptyset$\;
	$\mathit{period}\leftarrow{h}$\;
	$\mathit{next}\leftarrow\{(0,O_{1,j,t}) \mid j\in\{1,\dots,J\}\}$\;
	%	\lForEach{$m\in\{1,\dots,M\}$}{$f_m\leftarrow 0$}
	\While{$\mathit{next}\neq\emptyset$}{
		%	$\mathit{\tau}=\sum_{e\in\mathit{next}}\tau_e$\;
		\lForEach{$e\in\mathit{next}$}{%}
		$p_e\leftarrow \frac{\tau_e}{\sum_{e'\in\mathit{next}}\tau_{e'}}$}
	Randomly select an edge $e$ based on $p_e$\;
	$\mathit{end time}\leftarrow{e}$\;
	\For{selected edge $e=(O',O_{i,j,t})$}{
		$\mathit{e}\leftarrow{start time + process time}$\;
		\If{$\mathit{e}<{period}$}{countinue}
		$\mathit{sequence}.\mathrm{enqueue}(O_{i,j,t})$\;
		$\mathit{selected}\leftarrow\mathit{selected}\cup\{e\}$\;
		$\mathit{next}\leftarrow\{(O_1,O_2)\in\mathit{next} \mid O_2\neq O_{i,j,t}\}$\;
		$\begin{array}{@{}r@{}l@{}}
			E \leftarrow {} &		
			\{(O_{i,j,t},O_{{i+1},j,t'}) \mid i<n_j\}
			%	  \cup {}
			\\ {} \cup {} &
			\{(O_{i,j,t},O_{i',j',t}) \mid (O_1,O_{i',j',t})\in\mathit{next}\}\text{\;}
		\end{array}$
		$\mathit{next}\leftarrow\mathit{next}\cup E$\;
		}}
		\lForEach{$m\in\{1,\dots,M\}$}{$a_m\leftarrow 0$}
		\While{$\mathit{sequence}\neq[]$}{
			$O_{i,j,t}\leftarrow\mathit{sequence}.\mathrm{dequeue}()$\;
			$a \leftarrow \infty$\;
			%	$b \leftarrow 0$\;
			\ForEach{$m$ \KwFrom $1$ to \KwTo $M$}{
				\If{$t_m = t$ and $a_m < a$}{
					$a\leftarrow a_m$\;
					$b\leftarrow m$\;
				}
			}
			%	\If{$0<b$}{
				$\begin{array}{@{}r@{}l@{}}
					s_{i,j,t,b}\leftarrow 
					\max(&\{a\}
					\\ {} \cup {} &
					\{s_{i-1,j,t',m}+d_{i-1,j,t'}\mid{}i>1\})\text{\;}
				\end{array}
				$
				$a_b \leftarrow s_{i,j,t,b}+d_{i,j,t}$\;
				%	}
		}
		\Return $\langle\{s_{i,j,t,m} \mid (O',O_{i,j,t})\in\mathit{selected}\},{}$\rlap{$\mathit{selected}\rangle$\;}
\end{algorithm}

\subsubsection{GS Makespan}
To minimize makespan, the first phase constructs an ordered list of all operations within an SMSP instance, planned to schedule. This is achieved through a probabilistic decision-making rule derived from the pheromone matrix, which selects edges $(O',O_{i,j,t})$ and sequentially adds their target operations 
$O_{i,j,t}$ to the list. To ensure the feasibility of the resulting schedule, the prerequisite operation 
$O_{i-1,j,t'}$ for the same job~$j$ must already belong to the sequence in case $i>1$. 
This requirement is met by maintaining a set  $\mathit{next}$
of selectable conjunctive and disjunctive edges $(O',O_{i,j,t})$
such that $O'$ is the dummy start node~$0$ or already in sequence,
while $O_{i,j,t}$ is the first yet unsequenced operation of its job~$j$. 

The selection of an edge leading to an unsequenced operation continues until every operation and its corresponding targeting edge has been processed. It is important to note that the chosen disjunctive edges connect operations based on their tool groups, meaning they do not dictate the machine assignments, which are determined in the subsequent phase.

With a complete sequence of operations available, the second phase involves the allocation of each operation to the earliest available machine. This machine assignment step follows the order established in the first phase to create a feasible schedule that assigns machines and start times to all operations.

\subsubsection{GS Operations}
For optimizing operations, the first phase constructs a sequence comprising of all operations
of an SMSP instance that can fit in planning period.
Similarly, a probabilistic decision rule based on the pheromone
matrix selects edges $(O',O_{i,j,t})$
and adds their target operations $O_{i,j,t}$
to the sequence one by one. The operations can only be added to the sequence if the ending time is within the period $h$.
To ensure the feasibility of a resulting schedule,
the predecessor operation $O_{i-1,j,t'}$ of the same job~$j$
must already belong to the sequence in case $i>1$.
This is accomplished by maintaining a set $\mathit{next}$
of selectable conjunctive and disjunctive edges $(O',O_{i,j,t})$
such that $O'$ is the dummy start node~$0$ or already in sequence,
while $O_{i,j,t}$ is the first yet unsequenced operation of its job~$j$.

The process of selecting some edge to a yet unsequenced operation
is repeated until each operation along with an edge targeting it
has been processed.
Note that selected disjunctive edges link operations based on tool groups,
i.e., they do not reflect a machine assignment to be made in the second phase.

With a sequence of operations at hand,
the second phase allocates operations one by one to an earliest
available machine.
The machine assignment process allocates operations
according to the sequence from the first phase, yielding a
feasible schedule that assigns the machines and start times for all operations.

\subsection{Evaluation Module}
While each ant independently constructs a feasible schedule by means of the
GS procedure, the evaluation module collects the results obtained
by the ants in a GSACO iteration.
Among them, a schedule of shortest makespan is determined as outcome of the
iteration and stored as new best solution in case it improves over the schedules found in previous iterations (if any).
After evaporating pheromones~$\tau_e$ by $\rho\cdot\tau_e$,
where $\tau_z$ remains as minimum pheromone level if the obtained value
would be smaller,
the edges~$e$ that have been selected by the GS procedure for constructing the current best schedule receive a pheromone contribution and are updated to $\tau_e+c$.

Note that our contribution parameter $c$ is a constant,
while approaches in the literature often take the inverse of an objective value
\cite{turkyilmaz2020research}, i.e., of the makespan in our case.
The latter requires careful scaling to obtain non-marginal
pheromone contributions, in particular, when makespans get as large
as for SMSP instances.
We instead opt for pheromone contributions such that the
edges selected to construct best schedules are certain to have an increased chance
of getting re-selected in forthcoming iterations.

\section{Simulation}
\label{sec:sim}

To simulate a semiconductor fab, we adapted the simulator initially created by \cite{Kovács2022}, enhancing its capacity to handle the complexities and scalability challenges inherent in semiconductor manufacturing scheduling.

This simulator, tailored for the SMT2020 testbed, incorporates a comprehensive framework for generating diverse example datasets across multiple scales, crucial for the development and validation of innovative scheduling methods without the risk of overfitting. It operates using a dispatcher that dynamically allocates lots to machines based on predefined decision points, facilitating iterative simulation cycles that continue until designated performance benchmarks are achieved.

The dispatcher utilizes basic local rules such as First-In, First-Out (FIFO), Critical Ratio (CR), and Random selection to manage lot assignments efficiently. These rules serve as foundational strategies, ensuring basic operational efficiency. Additionally, we have integrated enhanced dispatching algorithms derived from the GSACO algorithm, which leverage more sophisticated decision-making processes to optimize scheduling tasks further. These enhancements not only improve the precision of the simulation but also significantly extend its applicability and effectiveness in complex manufacturing scenarios.

\begin{figure}[t]
	\includegraphics[width=\textwidth]{sim_framework.png}
	\caption{Simulator-Scheduler framework}
	\label{fig:ss}
\end{figure}


\section{\uppercase{Experimental Evaluation}}
\label{sec:results}

We implemented our GSACO algorithm in Python using PyTorch, as it handles tensor operations efficiently and provides a multiprocessing library for
parallelization, thus significantly speeding up the ants' execution of the GS procedure in each GSACO iteration.%
\footnote{The source code is publicly available in our GitHub repository:
\url{https://github.com/prosysscience/GSACO}}
The first challenge consists of determining suitable values for the input
parameters listed in Table~\ref{tab:parameters}, i.e.,
all parameters but the internally calculated pheromone level $\tau_e$ on edges~$e$.
We commit to the values given in Table~\ref{tab:p_value},
where a time limit~$l$ of $10$ minutes and a planning horizon~$n$ of
up to $5$ operations per job are plausible for SMSP instances
based on the SMT2020 dataset, whose stochastic events necessitate frequent
re-scheduling in practice.
For the initial pheromone level~$\tau_y$,
we start from value~$1$, and take $0.00001$ as the minimum $\tau_z$
to avoid going down to $0$, considering that the GS procedure can only
select edges with non-zero entries in the pheromone matrix.
The values for the number~$k$ of ants, the evaporation rate~$\rho$,
and the pheromone contribution~$c$ are more sophisticated to pick.
That is, we tuned these parameters in a trial-and-error process that,
starting from a baseline, inspects deviations of the final makespan and convergence speed obtained with iterative modifications.
Certainly, an automated approach would be desirable to
perform this task efficiently for new instance sets.%
%
\begin{table}[t]
\caption{GSACO input parameter values for optimizing makespan}\label{tab:p_value} \centering
\begin{tabular}{|l|l|}
	\hline
	Parameter & Value \\ \hline
	$o$ & $makespan$/$operations$        \\
	$s$ & $deterministic$/$dynamic$        \\
	$l$ & $5$        \\
	$n$ & $1$--$5$/$15$ \\
	$k$ & $10$ \\
	$\tau_{y}$ & $1$ \\
	$\tau_{z}$ & $0.00001$ \\
	%		$\alpha$ & 1  \\
	%		$\beta$ & 1     \\
	$\rho$ & $0.7$ \\
	$c$ & $0.5$ \\
	\hline
\end{tabular}
\end{table}


To compare GSACO with the state of the art in FJSSP solving,
we also run the CP solver OR-Tools (version 9.5) \cite{pediga23a},
while heuristic and meta-heuristic methods from the literature could not
be reproduced due to the inaccessibility of source code or tuned hyperparameters.
Note that CP approaches have been shown to be particularly effective among
exact optimization techniques for FJSSP \cite{kubec16a},
where the free and open-source solver OR-Tools excels
as serial winner of the Mi\-ni\-Zinc Challenge.\footnote{\url{https://www.minizinc.org/challenge}}

We performed our experiments on a TUXEDO Pulse 14 Gen1 machine
equipped with an 8-core AMD Ryzen 7 4800H processor at 2.9GHz and onboard
Radeon graphics card.


Table~\ref{tab:benchmarkresults} illustrates the strengths of CP models on a benchmark set of
small to medium-scale FJSSP instances \cite{arnaout2014two},
where the instances MK1--MK4 are due to 
\cite{brandimarte1993routing} and the remaining eight instances
have been introduced in
\cite{fattahi2007mathematical}.
In view of the small numbers $J$ and $M$ of jobs or machines, respectively,
in these classical FJSSP instances,
OR-Tools solves all of them to optimality within a few seconds,
so that the CP column shows the minimal makespan for each instance.
Since GSACO is an approximation method, its best schedules are not
necessarily optimal, as it can be observed on instances other than
SFJSSP1--SFJSSP4.
This reconfirms that exact models,
particularly those based on CP \cite{kubec16a},
are the first choice for FJSSP instances
of moderate size and complexity.%
%

To evaluate large-scale SMSP instances,
we consider two semiconductor production scenarios of the SMT2020 dataset:
Low-Volume/High-Mix (LV/HM) and High-Volume/Low-Mix (HV/LM).
As indicated in Table~\ref{tab:Dataset},
both scenarios include more than $2000$ jobs and more than $1300$ machines,
modeling the production processes of modern semiconductor fabs.
The main difference is given by the number of products and associated production routes for jobs, where LV/HM considers $10$ production routes varying between
$200$--$600$ steps in total, while HV/LM comprises $2$ production routes with about
$300$ or $600$ steps, respectively.
Originally, the LV/HM and HV/LM scenarios have been designed to represent fab load at the
start of simulation runs, so that the jobs are at different steps of their
production routes.
We here instead focus on scheduling for planning horizons~$n$ from~$1$ to~$5$,
standing for the up to $5$ next operations to be performed per job.
Hence, the operations $O$ to schedule gradually increase from the
number $J$ of jobs, in case of the planning horizon $n=1$,
% , given in Table~\ref{tab:Dataset},
to more than $10000$ operations % obtained
for the longest % planning 
horizon $n=5$.

\begin{table}[t]
\caption{Number of jobs, machines, and operations for SMSP instances}\label{tab:Dataset} \centering
\begin{tabular}{|l|c|c|c|}
	\hline
	Scenario & $J$    & $M$    & $O$              \\ \hline
	LV/HM    & $2156$ & $1313$ & up to $10747$    \\ 
	HV/LM    & $2256$ & $1443$ & up to $11218$    \\
	\hline
\end{tabular}
\end{table}
%

\begin{table}[]
	\caption{SMSP results obtained with GSACO}	\label{tab:results-operations} \centering
	\begin{tabular}{|l|cccccc|}
		\hline
		\multicolumn{1}{|c|}{\multirow{2}{*}{Instance}} &
		\multicolumn{6}{c|}{Planning period in hours} \\ \cline{2-7} 
		\multicolumn{1}{|c|}{} &
		\multicolumn{1}{c|}{1} &
		\multicolumn{1}{c|}{2} &
		\multicolumn{1}{c|}{3} &
		\multicolumn{1}{c|}{4} &
		\multicolumn{1}{c|}{5} &
		6 \\ \hline &
		\multicolumn{1}{l|}{Ops/Lots} &
		\multicolumn{1}{l|}{Ops/Lots} &
		\multicolumn{1}{l|}{Ops/Lots} &
		\multicolumn{1}{l|}{Ops/Lots} &
		\multicolumn{1}{c|}{Ops/Lots} &
		\multicolumn{1}{l|}{Ops/Lots} \\ \cline{2-7} 
		SMT2020\_HVLM &
		\multicolumn{1}{c|}{1848/0} &
		\multicolumn{1}{c|}{2960/0} &
		\multicolumn{1}{c|}{4093/1} &
		\multicolumn{1}{c|}{4970/3} &
		\multicolumn{1}{c|}{5975/5} &
		6716/7 \\
		SMT2020\_LVHM &
		\multicolumn{1}{c|}{-} &
		\multicolumn{1}{c|}{-} &
		\multicolumn{1}{c|}{-} &
		\multicolumn{1}{c|}{-} &
		\multicolumn{1}{c|}{-} &
		- \\ \hline
	\end{tabular}%
\end{table}


\begin{table*}[t]
	\caption{SMSP results obtained with CP and GSACO}\label{tab:results} \centering
	\begin{tabular}{|r|l|r|r|r|r|r|r|r|r|r|r|}
		\hline
		&
		&
		\multicolumn{2}{c}{$1$ min} &
		\multicolumn{2}{c}{$3$ min} &
		\multicolumn{2}{c}{$5$ min} &
		\multicolumn{2}{c}{$7$ min} &
		\multicolumn{2}{c}{$9$ min} \\ \cline{3-12} 
		$n$ & Scenario & CP & GSACO & CP & GSACO & CP & GSACO & CP & GSACO & CP & GSACO \\ \hline
		\multirow{2}{*}{$1$} & LV/HM & - & $3735$ & $18572$ & $3725$ & $3746$ & $3725$ & $3723$ & $3725$ & $3723$ & $3725$  \\
		& HV/LM & - & $1405$ & - & $1405$ & $2242$ & $1405$ & $1609$ & $1405$ & $1600$ & $1405$ \\
		\multirow{2}{*}{$2$} & LV/HM & - & $3773$ & - & $3751$ & - & $3750$ & - & $3739$ & $4398$ & $3739$ \\
		& HV/LM & - & $1653$ & - & $1644$ & - & $1611$ & - & $1611$ & - & $1611$   \\
		\multirow{2}{*}{$3$} & LV/HM & - & $3880$ & - & $3867$ & - & $3836$ & - & $3834$ & - & $3834$   \\
		& HV/LM & - & $1902$ & - & $1889$ & - & $1889$ & - & $1876$ & - & $1876$     \\
		\multirow{2}{*}{$4$} & LV/HM & - & $4578$ & - & $4540$ & - & $4540$ & - & $4540$ & - & $4540$     \\
		& HV/LM & - & $2207$ & - & $2113$ & - & $2113$ & - & $2093$ & - & $2093$  \\
		\multirow{2}{*}{$5$} & LV/HM & - & $4680$ & - & $4680$ & - & $4553$ & - & $4553$ & - & $4553$   \\	
		& HV/LM & - & $2667$ & - & $2566$ & - & $2566$ & - & $2518$ & - & $2518$ \\
		\hline  
	\end{tabular}
\end{table*}


\begin{table}[t]
	\caption{Throughput: Operations/Lots across different Planning Hours} \label{tab:my_label} \centering
	\begin{tabular}{|l|c|c|c|c|c|c|}
		\hline
		\textbf{Algorithm} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} \\ \cline{1-7} 
		Dispatcher (fifo)   & 1819/0 & 2846/0 & 4027/1 & 4916/4 & 5956/6 & 6822/8 \\
		Dispatcher (cr)     & 1801/0 & 2830/0 & 4028/1 & 4933/3 & 5994/5 & 6934/8 \\
		Dispatcher (random) & 1809/0 & 2884/0 & 4102/1 & 4976/3 & 6045/5 & 6954/7 \\
		Scheduler (gsaco)   & 1847/0 & 2960/0 & 4093/1 & 4970/3 & 5975/5 & 6716/7 \\
		\hline 
	\end{tabular}
\end{table}


\begin{table}[t]
	\caption{Percentage Change in Dispatcher Performance Over Planning Hours} \label{tab:dispatchers} \centering
	\begin{tabular}{|l|c|c|c|c|c|c|}
		\hline
		\textbf{Dispatcher} & \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} & \textbf{5} & \textbf{6} \\
		\hline 
		FIFO     & -    & -    & -    & -    & -    & -    \\
		CR       & -0.99\% & -0.56\% & 0.02\% & 0.35\% & 0.64\% & 1.64\% \\
		RANDOM   & -0.55\% & 1.33\% & 1.86\% & 1.22\% & 1.49\% & 1.93\% \\
		GSACO    & 0.72\% & 1.93\% & 3.43\% & 3.03\% & 2.19\% & 1.70\% \\
		\hline
	\end{tabular}
\end{table}


%
While running with a time limit $l$ of $10$ minutes,
Table~\ref{tab:results} reports the makespans of current best schedules
found by the CP solver OR-Tools and our GSACO implementation
at $1$, $3$, $5$, $7$, and $9$ minutes of computing time.
Considering that the SMSP instances are large,
OR-Tools now takes $3$ minutes to come up with the first solution(s)
for the shortest planning horizon $n=1$ on the LV/HM scenario.
Within the same fraction of computing time, GSACO already converges to a
makespan of $3725$ and then proceeds with iterations that do not
yield further improvements.
That the best schedule found by GSACO is not optimal is witnessed by a
marginally better solution obtained by OR-Tools after $7$ minutes.
However, for the other SMSP instances, OR-Tools is unable to improve over
GSACO within $9$ minutes, and it cannot even provide feasible schedules
for planning horizons from $n=2$ on the HV/LM scenario or $n=3$ 
on LV/HM.

The quick convergence of our GSACO implementation is also outlined by the makespan improvements plotted in Figure~\ref{fig:makespan}.
On the LV/HM scenario displayed in Figure~\ref{subfig:l}, 
GSACO obtains its best schedules within $7$ minutes
for all planning horizons.
Only for the longest planning horizon $n=5$
on the HV/LM scenario in Figure~\ref{subfig:h},
an improvement occurs after more than the $9$ minutes of computing time
listed in the rightmost column of Table~\ref{tab:results}.
Comparing the SMSP instances for which OR-Tools manages to provide
feasible schedules,
the convergence to makespans in roughly the range of GSACO's results
takes significantly more computing time.
Hence, the time limit that would be necessary to break even with GSACO,
as accomplished within $7$ minutes for the shortest planning horizon
$n=1$ on the LV/HM scenario,
cannot be predicted for the SMSP instances with longer planning horizons.
Moreover, we observe that the initial schedules obtained 
in the first GSACO iteration by some of the ants running in parallel are of relatively high quality, while
OR-Tools sometimes finds outliers as its first solutions.
This phenomenon occurs for the planning horizons $n=1$ and $n=2$
on the LV/HM or HV/LM scenario, respectively, where the latter
schedule of makespan $17664$ is found after more than $9$ minutes
and thus not listed in Table~\ref{tab:results}.


\begin{figure}[t]
	\centering
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{period_3600s.png}
		\caption{WIP flow}
		\label{fig:p1}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{period_7200s.png}
		\caption{WIP flow}
		\label{fig:p2}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{period_10800s.png}
		\caption{WIP flow}
		\label{fig:p3}
	\end{minipage}
\end{figure}

\begin{figure}[t]
	\centering
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{period_14400s.png}
		\caption{WIP flow}
		\label{fig:p4}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{period_18000s.png}
		\caption{WIP flow}
		\label{fig:p5}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{period_21600s.png}
		\caption{WIP flow}
		\label{fig:p6}
	\end{minipage}
\end{figure}


\begin{figure}[t]
	\centering
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{total_operations_3600s.png}
		\caption{WIP flow}
		\label{fig:o1}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{total_operations_7200s.png}
		\caption{WIP flow}
		\label{fig:o2}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{total_operations_10800s.png}
		\caption{WIP flow}
		\label{fig:o3}
	\end{minipage}
\end{figure}

\begin{figure}[t]
	\centering
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{total_operations_14400s.png}
		\caption{WIP flow}
		\label{fig:o4}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{total_operations_18000s.png}
		\caption{WIP flow}
		\label{fig:o5}
	\end{minipage}\hfill
	\begin{minipage}{0.32\textwidth}
		\includegraphics[width=\textwidth]{total_operations_21600s.png}
		\caption{WIP flow}
		\label{fig:o6}
	\end{minipage}
\end{figure}

The plots in Figure~\ref{fig:o1} to Figure~\ref{fig:o6} presents the performance of various dispatching rules—FIFO, CR, RANDOM, and GSACO—across different planning horizons ranging from 1 to 6 hours. Each plot illustrates the total number of operations dispatched by each rule within these time frames, offering a clear comparison of their efficiency and effectiveness in handling operational tasks within a semiconductor manufacturing.

The performance of dispatching rules based on specific operational times and goals are analyzed. While simpler rules like FIFO and CR are predictable and may perform adequately in stable environments, their performance can lag in more dynamic or complex scenarios where adaptive strategies like GSACO provide significant advantages. Random dispatching, surprisingly effective in some cases, suggests that stochastic elements might occasionally align with operational demands, although this method’s reliability is less consistent. GSACO’s consistently superior performance advocates for its use in environments where maximizing operational throughput is critical. This analysis not only aids in strategic decision-making but also highlights the potential for further refining these algorithms to enhance their applicability and effectiveness across various manufacturing contexts.

The plots in Figure~\ref{fig:p1} to Figure~\ref{fig:p6} illustrate the Work in Progress (WIP) flow across various dispatching rules—FIFO, CR, RANDOM, and GSACO —over different planning horizons ranging from 1 to 6 hours. Each bar demonstrates the minimum and maximum WIP levels reached during the simulation period under each dispatching rule, with the height of the bar indicating the variability or stability of the WIP flow.

FIFO shows the lowest range of WIP variability, suggesting consistent and predictable processing under this rule within the first hour. CR and Random display slightly higher variability, indicating a less stable WIP flow.
GSACO exhibits the highest range, potentially due to more aggressive reordering and optimization strategies that initially increase variability before stabilizing.

As the planning horizon extends to 2, 3, 4, 5, and 6 hours, all methods show an increase in the maximum WIP range. FIFO consistently maintains a relatively lower range of WIP compared to other methods, indicating its less dynamic but stable approach.
CR's performance exhibits moderate variability, reflecting its strategy of prioritizing jobs based on their deadlines, which might not always align with minimizing WIP.
Random shows a moderate to high variability, which aligns with its inherent unpredictability.
GSACO consistently demonstrates the highest variability. This could be attributed to its optimization processes, which might involve significant shifts in job prioritization and scheduling to achieve long-term efficiency, leading to larger fluctuations in WIP.



\section{Conclusion}
\label{sec:conclusion}

Modern semiconductor fabs are highly complex and dynamic production
environments, whose efficient operation by means of automated scheduling
and control systems constitutes a pressing research challenge.
In this work, we model the production processes of large-scale
semiconductor fabs in terms of the well-known FJSSP.
In contrast to classical FJSSP benchmarks,
this leads to large-scale scheduling problems,
even if short planning horizons cover only a fraction of the long
production routes with hundreds of operations.
The resulting size and complexity of large-scale SMSP instances
exceed the capabilities of common FJSSP solving methods.
We thus propose the GSACO algorithm combining probabilistic
operation sequencing with greedy machine assignment.
Its efficient implementation utilizing tensor operations and
parallel ant simulations enables GSACO's convergence to high-quality
solutions in short time.
In this way, GSACO overcomes the scalability limits of
exact optimization by means of a state-of-the-art CP approach
and achieves the performance required for frequent re-scheduling
in reaction to process deviations. % in physical fabs.


While simplified FJSSP models of semiconductor manufacturing processes
provide insights regarding the scalability of scheduling methods,
in future work, we aim at extending GSACO to incorporate the specific
conditions and functionalities of tools performing the production operations.
Such features include, e.g.,
machine setups to be equipped before performing operations,
preventive maintenance procedures for which a machine needs to stay idle, and
batch processing capacities to handle several production lots in one pass.
In practice, these specifics matter for machine assignment strategies
and should also be reflected in the respective greedy phase of GSACO.

Our second target of future work concerns the utilization of schedules 
found by GSACO for decision making and control within simulation models
of semiconductor fabs.
This goes along with the extension of optimization objectives to
practically relevant performance indicators, such as deadlines for the
completion of jobs and minimizing the tardiness.
In view of the dynamic nature of real-world production operations and
unpredictable stochastic events,
quantifying the improvements by optimized scheduling methods
requires their integration and evaluation in simulation.


\section*{Acknowledgments}

This work has been funded by the FFG project 894072 (SwarmIn).
We are grateful to the anonymous reviewers for constructive 
comments that helped to improve the presentation of this paper.




%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\input{bib.tex}
\end{document}
